dust some of this off or find other interesting bits see notes from past yrs
 used: berkeleyParser, opennlp(now part of:..nlp2rdf), stanford-parser.(CoreNLP), nyu?
  https://github.com/slavpetrov/berkeleyparser ; https://github.com/NLP2RDF http://site.nlp2rdf.org/

λ▶107 j2Lat43: /km3/nlp> tail ../.note
λ▶92 j2Lat43: /ai2/km3> cp km3.asd nlp.asd  ;then edit just a bit
λ▶108 j2Lat43: /km3/nlp> egrep -v "^;;" ../nlp.asd >nlp.asd
λ▶115 j2Lat43: /km3/nlp> ln -s . nlp  ;so I can work in this subdir for now
nlp.asd incl ../components http://www.cs.utexas.edu/users/mfkb/RKF/tree/ 
λ▶119 j2Lat43: /km3/nlp> cat ld.cl
(lkm3)
(defvar *fl2* (list-lines "../../vq.txt")) ;was from ../in before
;(defun get-fl2 (n) (nth n *fl2*))
(ql 'nlp)
(defun berk-n (n) (berk (get-fl2 n)))
;1-8133 returns sexp parse in a str 
 ;will get2see where/if rest of processing still here
(defun berk2n (n) (berk2 (get-fl2 n))) ;yes as real sexpr instead of in str
;will want to load the right&wrong answers as well
will add ld.cl vs parts of it here, but not all daily output yet
USER(5): consider opencyc if need be; http://localhost:3602/cgi-bin/cg?cb-start ~/Documents/www/www.opencyc.org/downloads/opencyc-owl
λ▶135 j15Lat43: /km3/nlp> ls1 sci/*/*.km >lsci.cl
 
;loaded sci kb, have more parsers, need ner map txt to concepts (that have relations)
; use kb wn slots&class names, get longest matches along this
λ▶6 f3Lat43: /km3/nlp> cp ld.cl nl2.cl
 
λ▶41 f3Lat43: /km3/nlp> mv nc.cl nc0.cl
λ▶42 f3Lat43: /km3/nlp> cp /home/bobak/lsp/git/LispUtils/nc.cl .
 
test IBM blumix (Watson) NLP http://www.alchemyapi.com/api/combined/urls.html ./py/.note: 
could make or alter a restful service that was not all alchemy 
want not only caching of final but of intermediate as some things build 
could get local km taxonomys re to the queries
 

Maarten van Gompel @proycon Released CLAM v2.1: Turn your #nlp command line tools into #restful webservices. Please upgrade! https://github.com/proycon/clam/releases/tag/v2.1.0 … 
 CLAM: Computational Linguistics Application Mediator 
 CLAM allows you to quickly and transparently transform your Natural Language Processing application into a RESTful webservice, with which both human end-users as well as automated clients can interact.  

=want to generalize, wrap MITIE, and use w/the tup.cl code
λ▶54 j9Lat43: /km3/nlp> cat mie/sample_text.txt | mie/ner_stream MITIE-models/english/ner_model.dat 
        A [ORGANIZATION Pegasus Airlines] plane landed at an [LOCATION Istanbul] airport Friday after a passenger ...
I really want relationships, want to look@ uw&(stanford's)openie too;as well as MITIE's relation_extraction_example
./relation_extraction_example MITIE-models/english/ner_model.dat MITIE-models/english/binary_relations/rel_classifier_location.location.contains.svm sample_text.txt

uw: https://github.com/knowitall/openie.git  also: http://nlp.stanford.edu/software/openie.html

http://nlp.stanford.edu/software/relationExtractor.shtml http://nlp.stanford.edu/software/stanford-dependencies.shtml 

https://gate.ac.uk/sale/talks/gate-course-may10/track-3/module-11-ml-adv/module-11-relations.pdf 

=an update of this w/the nlp.lisp 'sp' call or similar: http://nlp.stanford.edu/software/lex-parser.shtml http://nlp.stanford.edu/software/stanford-dependencies.shtml 
 piping not as standard&since I might want(a cleaner ver of)cachine in dir above, save a file w/in txt, run it, and have output added as the cached version
 could start w/a /tmp/sp.txt file  ;also had the netcat like code around, so maybe set up a service, but unlikely/to be needed at 1st
;when loading nlp.asd noticed prefixp commented out in util_mb I'm using, so there are some diff w/the one on github /resync more sometime
sp2 fnc gives cons tree but skips dependency info and other sentences ;if can get xml/json of this&more, it will be really easy ;look@~lemon encoding
sp_1 gives tree-parse of each sentence, &sp_2 adds the dependancy info for each(just as strings);want2break out into lemon like triples
break out stanford(&berk)parser parts of nlp.lisp and put into sp.lisp
https://site.nlp2rdf.org/ https://github.com/NLP2RDF/ ontologies/tree/master/vm/dep/stanford.{html|ttl} ;grep stanford: stanford.ttl &get into KM form
http://www.cs.utexas.edu/users/mfkb/RKF/{tree/ | trunktree/rkf-clib.tar.gz} core/text-*.km integrate w/nlp2rdf sp ttl slot hier
ln -s components/core cc ls1;cc/*Slot*|sed -f l.sed> ls.cl;ls1 cc/text-*|sed -f l.sed> lt.cl;l.sed: /^/s//(load-kb \"/ & /$/s//\")/
Have loaded KM slot-groups, and the core text-*.km files; also have stanford.ttl as a 1st cut hierarchy;not connected,nor the CoNLL(stanford)dependancy
 probably try for CoNLL to KM text-*.km part of it, &see how the stanford.ttl dependancy hierarchy fits in; start by hand &then try assited match
Keep looking for ppl having done this(maybe the ppl doing the lemon work)but not found yet, also look at other re work, a few incl:
also look@ https://github.com/yoavz/EDAN20-lab4  ;other than stanford, installed malt&mst parsers which also have CoNLL output,so can go from any of them
